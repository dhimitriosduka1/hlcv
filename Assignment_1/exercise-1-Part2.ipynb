{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import sklearn\n",
    "import sklearn.datasets \n",
    "import sklearn.svm as svm\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "# Tell matplotlib to show the plots within the notebook.\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "digits = sklearn.datasets.load_digits()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualize some images! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 4\n",
    "random_indices = [random.randint(0, len(digits.images)) for i in range(n)]\n",
    "\n",
    "fig, axes = plt.subplots(1, n, figsize=(40*1, 40*n))\n",
    "\n",
    "for _col, sample_idx in enumerate(random_indices):\n",
    "    img, lbl = digits.images[sample_idx], digits.target[sample_idx]\n",
    "    axes[_col].imshow(img)\n",
    "    axes[_col].set_xlabel(f\"Label: {lbl}\", fontsize=36) \n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_split(data, target, fraction):\n",
    "    ########  TODO ########################\n",
    "    # 1. Shuffle the data and targets\n",
    "    # 2. Split it based on the fraction\n",
    "    # 3. Return (train_1, target_1, train_2, target_2of two splits\n",
    "\n",
    "    data_train = target_train = data_test = target_test = None # Remove this\n",
    "    #######################################\n",
    "    return data_train, target_train, data_test, target_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_samples = len(digits.images)\n",
    "data = digits.images.reshape((n_samples, -1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into 50% train and 50% test subsets\n",
    "X_trainval, y_trainval, X_test, y_test = \\\n",
    "    train_test_split( \n",
    "        # TODO First separate the test samples!\n",
    "    )\n",
    "\n",
    "# Now Split the TRAIN data into 80% train and 20% cross-validation subsets\n",
    "X_train, y_train, X_val, y_val = \\\n",
    "    train_test_split( \n",
    "        # TODO Now separate the cross-validation samples!\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"{X_train.shape=} {y_train.shape=}\")\n",
    "print(f\"{X_val.shape=} {y_val.shape=}\")\n",
    "print(f\"{X_test.shape=} {y_test.shape=}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a classifier: a support vector classifier\n",
    "clf = svm.SVC(gamma=0.1)\n",
    "\n",
    "# Learn the digits on the train subset\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Predict the value of the digit on the val subset\n",
    "output = clf.decision_function(X_val)\n",
    "\n",
    "print(f\"Model output has shape {output.shape}\")\n",
    "\n",
    "\n",
    "########  TODO ########################\n",
    "# Use the (N, 10) outputs to get (N,) predictions (i.e class labels)\n",
    "preds = None\n",
    "########################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy_top1(predictions, targets):\n",
    "    ########  TODO ########################\n",
    "    # Return the mean accuracy (range from [0, 100])\n",
    "    return None # replace with accuracy\n",
    "    ########################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Cross-validation accuracy is {accuracy_top1(preds, y_val):0.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Go back to the previous cell and try different gamma values [0.1 0.01 0.001 0.0001 0.00001] for the classifier configuration and report results for each over the `val` set.\n",
    "\n",
    "\n",
    "Please write down your tested values and results here. Which gamma value worked best on the val set?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now insert your best gamma value and train the model again.\n",
    "best_gamma_value = None # Replace this with your best finding!\n",
    "\n",
    "clf = svm.SVC(gamma=best_gamma_value)\n",
    "# Learn the digits on the train subset\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Predict the value of the digit on the test subset\n",
    "output = clf.decision_function(X_test)\n",
    "\n",
    "########  TODO ########################\n",
    "# Use the (N, 10) outputs to get (N,) predictions (i.e class labels)\n",
    "\n",
    "########################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Final test accuracy is {accuracy_top1(preds, y_test):0.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax(x):\n",
    "    \"\"\"\n",
    "    Args       x: Numpy array of shape (N, num_classes) with real values\n",
    "    Returns    Numpy array of shape (N, num_classes) with softmax probability scores\n",
    "    \"\"\"\n",
    "    ########  TODO ########################\n",
    "    # return per-sample softmax scores\n",
    "    pass\n",
    "    ########################################\n",
    "\n",
    "########  TODO ########################\n",
    "# Using the softmax function defined above, convert (N, 10) outputs \n",
    "#to (N,) Softmax probabilities for the predicted class\n",
    "scores = []\n",
    "########################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualize some of the test predictions!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 6\n",
    "random_indices = [random.randint(0, len(X_test)) for i in range(n)]\n",
    "fig, axes = plt.subplots(1, n, figsize=(50*1, 50*n))\n",
    "\n",
    "\n",
    "for _col, sample_idx in enumerate(random_indices):\n",
    "    img = X_test[sample_idx].reshape((8, 8))\n",
    "    lbl = y_test[sample_idx]\n",
    "\n",
    "    axes[_col].imshow(img)\n",
    "    axes[_col].set_xlabel(\n",
    "        f\"{lbl}:  Pred: {preds[sample_idx]} Score: {scores[sample_idx]:0.3f}\",\n",
    "        fontsize=30\n",
    "    ) \n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
