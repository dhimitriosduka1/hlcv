{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dOokEbysdUsB",
        "outputId": "13b82de1-5543-45ec-f2af-fa587562420d"
      },
      "outputs": [],
      "source": [
        "# For Google Colab\n",
        "!pip install ultralytics\n",
        "!pip install roboflow\n",
        "!pip install -U transformers\n",
        "!pip install datasets\n",
        "!pip install wandb\n",
        "!pip install accelerate -U\n",
        "!pip install python-dotenv"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IbOKb7D1Of7g"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import shutil\n",
        "from datetime import datetime\n",
        "from gc import collect as garbage_collect\n",
        "from warnings import warn\n",
        "import wandb\n",
        "\n",
        "import torch\n",
        "import yaml\n",
        "from datasets import load_dataset\n",
        "from dotenv import load_dotenv\n",
        "from roboflow import Roboflow\n",
        "from torch.cuda import empty_cache as cuda_empty_cache\n",
        "from torch.cuda import mem_get_info\n",
        "from ultralytics import YOLO\n",
        "from wandb.integration.ultralytics import add_wandb_callback\n",
        "\n",
        "load_dotenv()  # load environment variables stored in .env file (e.g., API keys)\n",
        "\n",
        "# Useful constants\n",
        "CURRENT_DIR = os.getcwd()\n",
        "\n",
        "\n",
        "# Useful functions\n",
        "\n",
        "\n",
        "def clean_cache():\n",
        "    \"\"\"Cleans the GPU memory cache.\"\"\"\n",
        "    garbage_collect()\n",
        "    cuda_empty_cache()\n",
        "    mem_info = mem_get_info()\n",
        "    print(\n",
        "        f\"Freeing GPU Memory\\nFree: %d MB\\tTotal: %d MB\"\n",
        "        % (mem_info[0] // 1024**2, mem_info[1] // 1024**2)\n",
        "    )\n",
        "\n",
        "\n",
        "def safe_save(model: torch.nn.Module, final_model_path: str) -> None:\n",
        "    \"\"\"Saves a model to a file, ensuring that the file does not already exist. If it does, it\n",
        "    renames the existing file.\"\"\"\n",
        "    # Ensure the directory exists\n",
        "    os.makedirs(os.path.dirname(final_model_path), exist_ok=True)\n",
        "\n",
        "    if os.path.exists(final_model_path):\n",
        "        # Get current timestamp\n",
        "        timestamp = datetime.now().strftime(\"%Y%m%d_%H_%M_%S\")\n",
        "\n",
        "        # Split the path into directory, filename, and extension\n",
        "        directory, filename = os.path.split(final_model_path)\n",
        "        name, ext = os.path.splitext(filename)\n",
        "\n",
        "        # Create new filename with timestamp\n",
        "        new_filename = f\"{name}_{timestamp}{ext}\"\n",
        "        new_path = os.path.join(directory, new_filename)\n",
        "\n",
        "        warn(f\"{final_model_path} already exists. Renaming existing file to: {new_filename}\")\n",
        "\n",
        "        # Rename the existing file\n",
        "        shutil.move(final_model_path, new_path)\n",
        "\n",
        "    # Save the new model\n",
        "    model.save(final_model_path)\n",
        "    print(f\"New model saved as: {final_model_path}\")\n",
        "\n",
        "\n",
        "def load_config(config_path: str) -> dict:\n",
        "    \"\"\"Loads a YAML config file.\"\"\"\n",
        "    with open(config_path, \"r\") as file:\n",
        "        return yaml.safe_load(file)\n",
        "\n",
        "\n",
        "def to_path(*args):\n",
        "    \"\"\"Converts a list of strings into a path, from the current directory saved in `CURRENT_DIR`.\"\"\"\n",
        "    # If \"/\" is present in one of the strings, it is separated into a list of strings, such that we\n",
        "    # use the safe `os.path.join` function.\n",
        "    path_parts = []\n",
        "    for arg in args:\n",
        "        if '/' in arg:\n",
        "            path_parts.extend(arg.split('/'))\n",
        "        else:\n",
        "            path_parts.append(arg)\n",
        "\n",
        "    return os.path.join(CURRENT_DIR, *path_parts)\n",
        "\n",
        "\n",
        "def download_from(config: dict) -> None:\n",
        "    \"\"\"Downloads a dataset using the loaded `config`. It must have the following structure:\n",
        "\n",
        "    ```\n",
        "    data:\n",
        "        dataset: e.g., \"guitar-necks-detector\" or \"dduka/guitar-chords\" # The name of the dataset\n",
        "        load:\n",
        "            interface: \"roboflow\" or \"datasets\"\n",
        "            # (These must be available only if interface is \"roboflow\":)\n",
        "            workspace: \"...\"\n",
        "            project-version: \"1\"\n",
        "            version-download: \"...\"\n",
        "    ```\n",
        "    \"\"\"\n",
        "    if config[\"data\"][\"load\"][\"interface\"] == \"roboflow\":\n",
        "        # Test if a ROBOFLOW_API_KEY is available\n",
        "        if not os.getenv(\"ROBOFLOW_API_KEY\"):\n",
        "            from importlib.util import find_spec\n",
        "\n",
        "            if find_spec(\"google\"):\n",
        "                from google.colab import userdata\n",
        "                if userdata.get(\"ROBOFLOW_API_KEY\"):\n",
        "                    os.environ[\"ROBOFLOW_API_KEY\"] = userdata.get(\"ROBOFLOW_API_KEY\")\n",
        "            else:\n",
        "                raise ValueError(\n",
        "                    \"ROBOFLOW_API_KEY is not available in the environment variables. \"\n",
        "                    + \"Create a .env file in this directory with the key or in Google \"\n",
        "                    + \"Colab, add it to secret keys.\"\n",
        "                )\n",
        "\n",
        "        # Initialize Roboflow\n",
        "        rf = Roboflow(api_key=os.getenv(\"ROBOFLOW_API_KEY\"))\n",
        "\n",
        "        # Access the workspace and project\n",
        "        project = rf.workspace(config[\"data\"][\"load\"][\"workspace\"]).project(\n",
        "            config[\"data\"][\"dataset\"]\n",
        "        )\n",
        "        version = project.version(config[\"data\"][\"load\"][\"project-version\"])\n",
        "        dataset_path = to_path(config[\"data\"][\"dataset\"])\n",
        "        ds = version.download(config[\"data\"][\"load\"][\"version-download\"], location=dataset_path)\n",
        "    elif config[\"data\"][\"load\"][\"interface\"] == \"datasets\":\n",
        "        dataset_path = to_path(config[\"data\"][\"dataset\"])\n",
        "        ds = load_dataset(\"dduka/guitar-chords\", cache_dir=dataset_path)\n",
        "\n",
        "    return ds, dataset_path"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mSTAbZDidUsC"
      },
      "outputs": [],
      "source": [
        "f_run_config = \"config-yolo-v9.yml\"\n",
        "f_wandb_config = \"wandb.yml\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0GIl3WmidUsC"
      },
      "outputs": [],
      "source": [
        "# Load configuration\n",
        "config = load_config(f_run_config)\n",
        "wandb_config = load_config(f_wandb_config)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5AVOFm2odUsC",
        "outputId": "c383299c-1b06-4421-b34f-0b30451d0f74"
      },
      "outputs": [],
      "source": [
        "# Load the ds\n",
        "dataset, dataset_path = download_from(config)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "e_weE-HgOpDF",
        "outputId": "972c4a44-4cdc-4732-9c33-e2f07a49a726"
      },
      "outputs": [],
      "source": [
        "# Disable wandb for testing\n",
        "wandb.init(mode=\"disabled\")\n",
        "\n",
        "# Initialize the model\n",
        "model = YOLO(to_path(config['model']['name']))\n",
        "\n",
        "# Train the model\n",
        "results = model.train(\n",
        "    data=f\"{dataset_path}/data.yaml\",\n",
        "    imgsz=config['training']['imgsz'],\n",
        "    epochs=config['training']['epochs'],\n",
        "    project=None  # This disables wandb logging\n",
        ")\n",
        "\n",
        "# Save the final model\n",
        "safe_save(model, to_path(config['training']['final_model_path']))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "UNPEGlIIdUsD"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "image 1/1 /home/camilo/Repositorios/hlcv/Project/images/test.jpeg: 384x640 1 Guitar-necks, 9.5ms\n",
            "Speed: 0.6ms preprocess, 9.5ms inference, 75.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/predict3\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "from ultralytics import YOLO\n",
        "\n",
        "model = YOLO(\"/home/camilo/Repositorios/hlcv/Project/src/fretboard-recognition/final_models/best.pt\")\n",
        "results = model.predict(\"/home/camilo/Repositorios/hlcv/Project/images/test.jpeg\", save=True, conf=0.7)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
