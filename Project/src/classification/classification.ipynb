{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import yaml\n",
    "import json\n",
    "import wandb\n",
    "import torch\n",
    "import shutil\n",
    "import torchvision\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from PIL import Image\n",
    "from roboflow import Roboflow\n",
    "from torch.utils.data import Dataset\n",
    "from torchvision import transforms, datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "from datasets import load_dataset, DatasetDict, load_metric\n",
    "from transformers import ViTForImageClassification, ViTImageProcessor, TrainingArguments, Trainer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ChordsDataset(Dataset):\n",
    "    def __init__(self, root_dir, annotation_file, transform=None):\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "        \n",
    "        with open(annotation_file, 'r') as f:\n",
    "            self.coco = json.load(f)\n",
    "        \n",
    "        self.images = self.coco['images']\n",
    "        self.annotations = self.coco['annotations']\n",
    "        self.categories = self.coco['categories']\n",
    "\n",
    "        self.images = {img['id']: img for img in self.images}\n",
    "\n",
    "        self.nr_of_classes = len(self.categories)\n",
    "\n",
    "        # Create a mapping from image_id to annotations\n",
    "        self.image_to_label = {}\n",
    "        for annotation in self.annotations:\n",
    "            img = self.images[annotation['image_id']]\n",
    "            self.image_to_label[img[\"id\"]] = {\n",
    "                \"file_name\": img[\"file_name\"],\n",
    "                \"category\": annotation[\"category_id\"]\n",
    "            }\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        metadata = self.image_to_label[idx]\n",
    "        img_path = os.path.join(self.root_dir, metadata[\"file_name\"])\n",
    "        image = Image.open(img_path).convert('RGB')        \n",
    "        \n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        # Convert labels to tensor\n",
    "        return {\n",
    "            \"image\": image,\n",
    "            \"label\": torch.tensor(metadata[\"category\"]),\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_roboflow_data(config):\n",
    "    \"\"\"\n",
    "    Download dataset from RoboFlow.\n",
    "    \"\"\"\n",
    "    roboflow_config = config['data']['roboflow']\n",
    "    roboflow = Roboflow(api_key=roboflow_config[\"api_key\"])\n",
    "    project = roboflow.workspace(roboflow_config[\"workspace\"]).project(roboflow_config[\"project\"])\n",
    "    version = project.version(roboflow_config[\"version\"])\n",
    "    dataset = version.download(model_format=roboflow_config[\"version_download\"])\n",
    "\n",
    "    dest_path = config['data']['path'] + \"/\" + dataset.name\n",
    "\n",
    "    if not os.path.exists(dest_path):\n",
    "        shutil.move(src=dataset.location, dst=dest_path)\n",
    "\n",
    "    print(f\"Dataset downloaded and extracted to {config['data']['path']}\")\n",
    "    return dataset, dest_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_config(config_path):\n",
    "    with open(config_path, 'r') as file:\n",
    "        return yaml.safe_load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_transform(aug_config, processor):\n",
    "    transform_list = []\n",
    "    \n",
    "    # Add transforms based on configuration\n",
    "    # if 'random_resize_crop' in aug_config:\n",
    "    #     transform_list.append(transforms.RandomResizedCrop(**aug_config['random_resize_crop']))\n",
    "    # if 'random_horizontal_flip' in aug_config:\n",
    "    #     transform_list.append(transforms.RandomHorizontalFlip(aug_config['random_horizontal_flip']))\n",
    "    # if 'color_jitter' in aug_config:\n",
    "    #     transform_list.append(transforms.ColorJitter(**aug_config['color_jitter']))\n",
    "    # if 'random_rotation' in aug_config:\n",
    "    #     transform_list.append(transforms.RandomRotation(aug_config['random_rotation']))\n",
    "    \n",
    "    # Always include resizing, ToTensor, and normalization\n",
    "    transform_list.extend([\n",
    "        transforms.Resize((224, 224)),\n",
    "        transforms.ToTensor(),\n",
    "        # transforms.Normalize(mean=processor.image_mean, std=processor.image_std),\n",
    "    ])\n",
    "    \n",
    "    return transforms.Compose(transform_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_transforms(config, processor):\n",
    "    train_transform = create_transform(config['data']['train_augmentation'], processor)\n",
    "    val_transform = create_transform(config['data'].get('val_augmentation', {}), processor)\n",
    "    \n",
    "    return train_transform, val_transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(data_dir, transform):\n",
    "    return datasets.ImageFolder(data_dir, transform=transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def organize_images_by_class(root_dir, destination):\n",
    "    # List of subdirectories to process\n",
    "    subdirs = ['train', 'valid', 'test']\n",
    "    \n",
    "    # Process all images from train, valid, and test directories    \n",
    "    for subdir in subdirs:\n",
    "        dir_path = os.path.join(root_dir, subdir)\n",
    "        \n",
    "        # Skip if the directory doesn't exist\n",
    "        if not os.path.exists(dir_path):\n",
    "            print(f\"Directory {dir_path} not found. Skipping...\")\n",
    "            continue\n",
    "\n",
    "        # Get all image files in the directory\n",
    "        image_files = [f for f in os.listdir(dir_path) if f.lower().endswith(('.png', '.jpg', '.jpeg', '.gif', '.bmp'))]\n",
    "\n",
    "        # Move and organize images\n",
    "        for img in image_files:\n",
    "            first_letter = img[0].upper()\n",
    "            letter_dir = os.path.join(destination, first_letter)\n",
    "            \n",
    "            # Create letter directory if it doesn't exist\n",
    "            os.makedirs(letter_dir, exist_ok=True)\n",
    "\n",
    "    print(\"Image organization complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "f_run_config = \"config.yml\"\n",
    "f_wandb_config = \"wandb.yml\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load configuration\n",
    "config = load_config(f_run_config)\n",
    "wandb_config = load_config(f_wandb_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading Roboflow workspace...\n",
      "loading Roboflow project...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading Dataset Version Zip in Guitar-Chord-1 to coco:: 100%|██████████| 166698/166698 [00:24<00:00, 6725.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Extracting Dataset Version Zip to Guitar-Chord-1 in coco:: 100%|██████████| 2525/2525 [00:00<00:00, 4127.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset downloaded and extracted to ./Project/src/classification/dataset\n"
     ]
    },
    {
     "ename": "PermissionError",
     "evalue": "[Errno 13] Permission denied: '/datasets'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mPermissionError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[21], line 7\u001b[0m\n\u001b[1;32m      3\u001b[0m     _, location \u001b[38;5;241m=\u001b[39m download_roboflow_data(config)\n\u001b[1;32m      5\u001b[0m destination \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/datasets/\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m----> 7\u001b[0m \u001b[43morganize_images_by_class\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlocation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdestination\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[18], line 27\u001b[0m, in \u001b[0;36morganize_images_by_class\u001b[0;34m(root_dir, destination)\u001b[0m\n\u001b[1;32m     24\u001b[0m         letter_dir \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(destination, first_letter)\n\u001b[1;32m     26\u001b[0m         \u001b[38;5;66;03m# Create letter directory if it doesn't exist\u001b[39;00m\n\u001b[0;32m---> 27\u001b[0m         \u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmakedirs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mletter_dir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexist_ok\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m     29\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mImage organization complete!\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m<frozen os>:215\u001b[0m, in \u001b[0;36mmakedirs\u001b[0;34m(name, mode, exist_ok)\u001b[0m\n",
      "File \u001b[0;32m<frozen os>:225\u001b[0m, in \u001b[0;36mmakedirs\u001b[0;34m(name, mode, exist_ok)\u001b[0m\n",
      "\u001b[0;31mPermissionError\u001b[0m: [Errno 13] Permission denied: '/datasets'"
     ]
    }
   ],
   "source": [
    "# Download data from RoboFlow if specified\n",
    "if config['data'].get('use_roboflow', False):\n",
    "    _, location = download_roboflow_data(config)\n",
    "\n",
    "destination = \"/datasets\"\n",
    "\n",
    "organize_images_by_class(location, destination)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize wandb\n",
    "wandb.require(\"core\")\n",
    "wandb.init(\n",
    "    project=wandb_config[\"project\"],\n",
    "    name=wandb_config['name'] + \"-\" + wandb.util.generate_id(),\n",
    "    config=wandb_conf,\n",
    "    entity=wandb_config[\"entity\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " # Load pre-trained model and processor\n",
    "model = ViTForImageClassification.from_pretrained(config['model']['pretrained_weights'])\n",
    "processor = ViTImageProcessor.from_pretrained(config['model']['pretrained_weights'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get transforms\n",
    "train_transform, base_transform = get_transforms(config, processor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the ds\n",
    "root_dir = 'path/to/custom_dataset'\n",
    "ds = load_dataset(\"imagefolder\", data_dir=root_dir)\n",
    "\n",
    "# Split the data\n",
    "ds = ds['train'].train_test_split(test_size=0.3, stratify_by_column=\"label\")  # 70% train, 30% test\n",
    "ds_test = ds['test'].train_test_split(test_size=0.5, stratify_by_column=\"label\")  # 30% test --> 15% valid, 15% test\n",
    "ds = DatasetDict({\n",
    "    'train': ds['train'],\n",
    "    'test': ds_test['test'],\n",
    "    'valid': ds_test['train']\n",
    "})\n",
    "    \n",
    "del ds_test\n",
    "\n",
    "ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define training arguments\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=config['training']['output_dir'],\n",
    "    num_train_epochs=config['training']['num_epochs'],\n",
    "    per_device_train_batch_size=config['training']['batch_size'],\n",
    "    per_device_eval_batch_size=config['training']['batch_size'],\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    learning_rate=float(config['training']['learning_rate']),\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"accuracy\",\n",
    "    report_to=\"wandb\",\n",
    ")\n",
    "\n",
    "# Define Trainer\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_ds,\n",
    "    eval_dataset=valid_ds,\n",
    "    compute_metrics=lambda p: {\"accuracy\": (p.predictions.argmax(-1) == p.label_ids).mean()},\n",
    ")\n",
    "\n",
    "# # # Train the model\n",
    "trainer.train()\n",
    "\n",
    "# # Save the fine-tuned model\n",
    "# trainer.save_model(config['training']['final_model_path'])\n",
    "\n",
    "# # Close wandb run\n",
    "# wandb.finish()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hlcv-project",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
