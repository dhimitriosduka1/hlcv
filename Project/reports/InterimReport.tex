% CVPR 2023 Paper Template
% based on the CVPR template provided by Ming-Ming Cheng (https://github.com/MCG-NKU/CVPR_Template)
% modified and extended by Stefan Roth (stefan.roth@NOSPAMtu-darmstadt.de)

\documentclass[10pt,twocolumn,letterpaper]{article}

%%%%%%%%% PAPER TYPE  - PLEASE UPDATE FOR FINAL VERSION
\usepackage{cvpr}      % To produce the REVIEW version


% Include other packages here, before hyperref.
\usepackage{graphicx}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{booktabs}


% It is strongly recommended to use hyperref, especially for the review version.
% hyperref with option pagebackref eases the reviewers' job.
% Please disable hyperref *only* if you encounter grave issues, e.g. with the
% file validation for the camera-ready version.
%
% If you comment hyperref and then uncomment it, you should delete
% ReviewTempalte.aux before re-running LaTeX.
% (Or just hit 'q' on the first LaTeX run, let it finish, and you
%  should be clear).
\usepackage[pagebackref,breaklinks,colorlinks]{hyperref}


% Support for easy cross-referencing
\usepackage[capitalize]{cleveref}
\crefname{section}{Sec.}{Secs.}
\Crefname{section}{Section}{Sections}
\Crefname{table}{Table}{Tables}
\crefname{table}{Tab.}{Tabs.}


%%%%%%%%% PAPER ID  - PLEASE UPDATE
\def\cvprPaperID{*****} % *** Enter the CVPR Paper ID here
\def\confName{CVPR}
\def\confYear{2023}


\begin{document}

%%%%%%%%% TITLE - PLEASE UPDATE
\title{Team \#16: Interim Report} 

\author{
 Camilo Mart√≠nez\\
 7057573\\
    \and
 Dhimitrios Duka\\
 7059153\\
    \and
 Honglu Ma\\
 7055053\\
}
\maketitle

%%%%%%%%% BODY TEXT
\section{Progress Report}


\subsection{Creation of a custom dataset}
The datasets that we were able to find lacked some of the data that we needed in our training. This consited mostly of minor chords (Am, Dm, Em, etc.). To solve this issue, we decided to create our own dataset. The setup was simple. First, we recordered each a video for each chords using a smartphone. Each of the videos were shot in 60fps so that the each retreived frame would be of high quality and not subject to bluring. Each video was shot in 4k UHD and then downsampled to 640x360. In each frame we made sure that the freatboad was obvious so that spatial information could also be encoded from our classifier. Then, we wrote a script which would extract the frames from the video and save them as images. In total, for each chord we had around 5000 frames, so we decided to use only 1 in 5 frames so that we increase the diversity of the dataset. As far as vlaidation and testing goes,
we will first try to use the previously mentioned datasets. However, we are expecting some issues because there could be different data distributions between the datasets. If this is the case, we will have to create our own validation and testing datasets as well.



\section{Problems Encountered}
The problems that we encountered are more of the technial nature. Maybe we can mention the problem with YOLO here where we removed every other class and we got a very high but not true accuracy. 

Another problem was realted to teaining the model. We faced some issues with the provided cluster, but after some trial and errors, we were able to fix it and submit jobs to it. 

%%%%%%%%% REFERENCES
{\small
\bibliographystyle{ieee_fullname}
\bibliography{references}
}

\end{document}
