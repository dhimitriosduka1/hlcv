% CVPR 2023 Paper Template
% based on the CVPR template provided by Ming-Ming Cheng (https://github.com/MCG-NKU/CVPR_Template)
% modified and extended by Stefan Roth (stefan.roth@NOSPAMtu-darmstadt.de)

\documentclass[10pt,twocolumn,letterpaper]{article}

%%%%%%%%% PAPER TYPE  - PLEASE UPDATE FOR FINAL VERSION
\usepackage{cvpr}      % To produce the REVIEW version


% Include other packages here, before hyperref.
\usepackage{graphicx}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{booktabs}


% It is strongly recommended to use hyperref, especially for the review version.
% hyperref with option pagebackref eases the reviewers' job.
% Please disable hyperref *only* if you encounter grave issues, e.g. with the
% file validation for the camera-ready version.
%
% If you comment hyperref and then uncomment it, you should delete
% ReviewTempalte.aux before re-running LaTeX.
% (Or just hit 'q' on the first LaTeX run, let it finish, and you
%  should be clear).
\usepackage[pagebackref,breaklinks,colorlinks]{hyperref}


% Support for easy cross-referencing
\usepackage[capitalize]{cleveref}
\crefname{section}{Sec.}{Secs.}
\Crefname{section}{Section}{Sections}
\Crefname{table}{Table}{Tables}
\crefname{table}{Tab.}{Tabs.}


%%%%%%%%% PAPER ID  - PLEASE UPDATE
\def\cvprPaperID{*****} % *** Enter the CVPR Paper ID here
\def\confName{CVPR}
\def\confYear{2023}


\begin{document}

%%%%%%%%% TITLE - PLEASE UPDATE
\title{Team \#16: Interim Report} 

\author{
 Camilo Mart√≠nez\\
 7057573\\
    \and
 Dhimitrios Duka\\
 7059153\\
    \and
 Honglu Ma\\
 7055053\\
}
\maketitle

%%%%%%%%% BODY TEXT
\section{Progress Report}


\subsection{Creation of a custom dataset for chord classification}
In the original paper, the authors train the models in a custom dataset that contains 14 classes (A, Am, B, Bm, C, Cm, D, Dm, E, Em, F, Fm, G, Gm). However, the datasets that we were able to find lacked some of them, mainly the minor chords. We employed two solutions to this problem. First, we enriched the dataset that we found by adding the missing classes. Second, we created our dataset. The setup was simple. First, a video for each chord was recorded using a smartphone. Each of the videos was 1:30 minutes long and was shot in 4k 60fps so that each retrieved frame would be of high quality and not subject to blurring. Second, we extracted each frame from the video and saved it as a downsampled image of size 640x360. In total, for each chord we had around 5000 frames, so we decided to use only 1 in 5 frames to reduce the overlap of the samples as much as possible. However, we still think that the sample overlapping could be an issue, so we will record more videos for each chord in the future.

\subsection{Fine-tuning ViT for chord classification}
We tried to fine-tune the Vision Transformer (ViT) model for chord classification using different approaches.

\subsubsection{Training only the MLP head}
We first tried fine-tuning only the MLP head of ViT. This was done by freezing the weights of the model and only training the weights and biases of the classifier. We suspect that the pre-trained model is not able to capture the features of our inputs and the extended MLP head is merely trying to predict the labels on its own i.e. the same as a feed-forward network. We also tried to unfreeze more layers of the model and they also didn't meet the expectation but the accuracy did increase which sort of confirms our suspicion.

\subsubsection{Full Fine Tuning}
In our next approach, we implemented full fine-tuning of the entire model. This process involved specifying the labels of our inputs to the pre-trained model, which then automatically attached a new Multi-Layer Perceptron (MLP) head to its classifier. The results of this method were encouraging, as we observed a good performance on our task. Most notably, we achieved an accuracy of 86\% on the validation set.

\subsubsection{Using PEFT methods}
As our next step, we are also planning to use PEFT method to fine-tune the model. Specifically, we plan to use LoRA to reduce the number of parameters. We are still in the process of trying this method and we are expecting to see some improvements in training time without compromising on accuracy.

\section{Problems Encountered}
We encountered several issues during our work. Firstly, we faced some problems with the cluster. At first, we could not configure a conda environment or run our code. After some debugging, we were able to solve the problem by installing the packages in chunks instead of all at once.

Second, we faced some problems while fine-tuning YOLOv9 for fretboard detection. At first, we were using Ultralytics to fine-tune the model. However, we noticed that the final model recognized only two classes: the fretboard and the background. This meant that the model was forgetting all other classes on which it was trained. We addressed this problem by implementing another approach based on \cite{}.

Lastly, during the classification phase, we faced some problems with data leakage. We noticed a rather high classification accuracy of 99\% in the validation set which was surprising to us. After some debugging, we found out that the problem originated from the preprocessing that we had applied to our classification dataset.


%%%%%%%%% REFERENCES
{\small
\bibliographystyle{ieee_fullname}
\bibliography{references}
}

\end{document}
